# .env
LLM_MODEL=llama3
OPENAI_MODEL=gpt-4
OPENAI_API_KEY=sk-...
OLLAMA_URL=http://localhost:11434/api/generate
LLM_BACKEND=ollama
# OLLAMA_BASE_URL is set by docker-compose.yml for containers. Use http://localhost:11434 only for local host testing.
